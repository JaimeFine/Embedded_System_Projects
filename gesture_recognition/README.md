# Raspberry Pi Camera Gesture Recognition

This project implements **real-time hand gesture recognition** on a Raspberry Pi using the **PiCamera2**, **OpenCV**, and **MediaPipe** for hand tracking, combined with a **scikit-learn SVM classifier**.
It allows you to **capture hand landmark data**, **train a gesture recognition model**, and **perform live gesture classification**.

## ğŸ“¦ Features

* âœ… **Hand Landmark Capture** â€“ Record landmark data for different gestures using MediaPipe.
* âš™ï¸ **Custom Gesture Training** â€“ Train your own SVM model on collected gestures.
* ğŸ¥ **Real-Time Recognition** â€“ Recognize gestures from live PiCamera2 input and overlay results on the video feed.

## ğŸ› ï¸ Installation

```bash
# Clone the repo
git clone https://github.com/yourusername/raspberry-pi-gesture-recognition.git
cd raspberry-pi-gesture-recognition

# Install dependencies
pip install [dependencies]
```

> Dependencies include:
>
> * `opencv-python`
> * `mediapipe`
> * `numpy`
> * `scikit-learn`
> * `picamera2`

## â–¶ï¸ Usage

### 1. Capture Gesture Data

Run the capture script to log landmark data for a specific gesture (e.g., 5-finger hand):

```bash
python src/gesture_capture.py
```

ğŸ‘‰ Saves data as `.npy` files inside `gesture_recognition_pack/`.

### 2. Train the Model

After collecting gesture datasets:

```bash
python src/training_program.py
```

ğŸ‘‰ Outputs `svm_model.pkl` (your trained classifier).

### 3. Recognize Gestures in Real-Time

```bash
python src/gesture_recognition.py
```

ğŸ‘‰ Displays PiCamera feed with recognized gestures (`Hand`, `Fist`, `Thumb`, `2Finger`, `3Finger`, `4Finger`, `5Finger`).
Press **q** to quit.

### 4. Logging Hand Data (optional)

```bash
python src/logging_hand_data.py
```

ğŸ‘‰ Continuously logs landmarks with visualization.

## âš™ï¸ Configuration

Adjust paths and filenames for `.npy` gesture datasets or `svm_model.pkl` inside the scripts if needed.

Default gesture classes:

```
0 â€“ Hand
1 â€“ Fist
2 â€“ Thumb
3 â€“ 2Finger
4 â€“ 3Finger
5 â€“ 4Finger
6 â€“ 5Finger
```

## ğŸ§  Code Structure

```
src/
â”œâ”€â”€ gesture_capture.py          # Capture landmark data for a gesture
â”œâ”€â”€ logging_hand_data.py        # Live logging of landmarks
â”œâ”€â”€ training_program.py         # Train SVM model on captured gestures
â”œâ”€â”€ gesture_recognition.py      # Real-time gesture recognition
â””â”€â”€ gesture_recognition_pack/   # Stores .npy datasets & trained model

```

## ğŸ¤ Contributing

We welcome contributions! Hereâ€™s how to get started:

1. ğŸ´ Fork the repo
2. ğŸ› ï¸ Create your feature branch (`git checkout -b feature/foo`)
3. âœ… Commit your changes (`git commit -am 'Add foo feature'`)
4. ğŸš€ Push to the branch (`git push origin feature/foo`)
5. ğŸ“¬ Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.
